# BitProphet
HKUST BDT 5001 Team Project



My model is based on Informer, which comes from the best paper in the 2021 AAAI. As we all know, long-sequence time-series forecasting demands a high prediction capacity of the model. Informer designed a transformer-based model to solve that. It has two excellent advantages. First, attention is all you need, another one is that Informer significantly decreases the time complexity and memory usage by re-designed the encoder and decoder. That's all.
